apiVersion: v1
kind: Template
metadata:
  name: selectorsyncset-template
objects:
- apiVersion: hive.openshift.io/v1alpha1
  kind: SelectorSyncSet
  metadata:
    generation: 1
    labels:
      managed.openshift.io/gitHash: 43ffb15
      managed.openshift.io/osd: 'true'
    name: osd-managed-prometheus-exporter-ebs-iops-reporter
  spec:
    clusterDeploymentSelector:
      matchLabels:
        api.openshift.com/managed: 'true'
    resourceApplyMode: sync
    resources:
    - apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: sre-ebs-iops-reporter
        namespace: openshift-monitoring
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: sre-ebs-iops-reporter
        namespace: openshift-monitoring
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: edit
      subjects:
      - kind: ServiceAccount
        name: sre-ebs-iops-reporter
        namespace: openshift-monitoring
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: sre-allow-read-machine-info
      rules:
      - apiGroups:
        - machine.openshift.io
        resources:
        - machines
        verbs:
        - get
        - list
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: sre-ebs-iops-reporter-read-machine-info
        namespace: openshift-machine-api
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: sre-allow-read-machine-info
      subjects:
      - kind: ServiceAccount
        name: sre-ebs-iops-reporter
        namespace: openshift-monitoring
    - apiVersion: cloudcredential.openshift.io/v1
      kind: CredentialsRequest
      metadata:
        name: sre-ebs-iops-reporter-aws-credentials
        namespace: openshift-monitoring
      spec:
        providerSpec:
          apiVersion: cloudcredential.openshift.io/v1
          kind: AWSProviderSpec
          statementEntries:
          - action:
            - cloudwatch:ListMetrics
            - cloudwatch:GetMetricData
            effect: Allow
            resource: '*'
        secretRef:
          name: sre-ebs-iops-reporter-aws-credentials
          namespace: openshift-monitoring
    - apiVersion: v1
      data:
        main.py: "#!/usr/bin/env python\n\nfrom sets import Set\n\nimport argparse\n\
          import boto3\nimport datetime\nimport logging\nimport os\nimport re\nimport\
          \ time\n\nfrom prometheus_client import start_http_server, Gauge\n\nEBS_IOPS\
          \ = Gauge(\"ebs_iops_credits\",\"Percent of burstable IOPS credit available\"\
          , labelnames=['vol_id'])\n\n# A list (implemented as a Set) of all active\
          \ volumes. \nACTIVE_VOLUMES = Set([])\n\n# Period in minutes from cloudwatch\
          \ to request\n# See https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_GetMetricData.html\n\
          CLOUDWATCH_PERIOD = 5\n\ndef chunks(l,n):\n    \"\"\"\n    Chunks up an\
          \ array +l+ into chunks of +n+ size\n    Based on https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n\
          \    \"\"\"\n    for i in xrange(0,len(l),n):\n        yield l[i:i+n]\n\n\
          def round_time(period):\n    \"\"\"\n    Round the current date (in utc)\
          \ to the nearest +period+ minutes. \n    For example, if the current time\
          \ is 16:23 and +period+ is 10 (minutes), the\n    return time will be 16:20.\n\
          \    Based on:\n    https://stackoverflow.com/questions/3463930/how-to-round-the-minute-of-a-datetime-object-python\n\
          \    \"\"\"\n    t = datetime.datetime.utcnow()\n    t += datetime.timedelta(minutes=period/2.0)\n\
          \    t -= datetime.timedelta(minutes=t.minute % period,\n              \
          \              seconds=t.second,\n                            microseconds=t.microsecond)\n\
          \    return t\n\ndef collect(aws):\n    \"\"\"\n    Collect the current\
          \ data from the AWS API\n    \"\"\"\n    \n    # All the volumes CloudWatch\
          \ tells us it knows about (whether or not it has data)\n    volumes = Set([])\n\
          \    \n    # List of volumes that we've actually had data back for the API\n\
          \    seen_volumes = Set([])\n\n    # get all the volume IDs. Note, not all\
          \ of these will necessarily have metrics\n    volumePager = cw.get_paginator('list_metrics')\n\
          \    for p in volumePager.paginate(MetricName='BurstBalance',Namespace='AWS/EBS'):\n\
          \        for v in p['Metrics']:\n            volumes.add(v['Dimensions'][0]['Value'])\n\
          \n    dimensionCriteria = []\n    for volume in list(volumes):\n       \
          \ dimensionCriteria.append({\n                'Id': re.sub(r'^vol-',\"vol_\"\
          ,volume,0),\n                'MetricStat': {\n                    'Metric':\
          \ {\n                        'Namespace': 'AWS/EBS',\n                 \
          \       'MetricName': 'BurstBalance',\n                        'Dimensions':\
          \ [\n                            {\n                                'Name':\
          \ 'VolumeId', 'Value': volume\n                            }\n         \
          \               ]\n                    },\n                    'Period':\
          \ CLOUDWATCH_PERIOD * 60,\n                    'Stat': 'Average',\n    \
          \                'Unit': 'Percent',\n                }\n            }\n\
          \        )\n\n    # get data for all the volume IDs\n    volumeDataPager\
          \ = cw.get_paginator('get_metric_data')\n    time_start = round_time(CLOUDWATCH_PERIOD)\n\
          \    logging.debug(\"Requesting from %s to %s with period of %d minutes\"\
          ,\n        time_start-(datetime.timedelta(minutes=CLOUDWATCH_PERIOD) * 2),\n\
          \        time_start-datetime.timedelta(minutes=CLOUDWATCH_PERIOD),\n   \
          \     CLOUDWATCH_PERIOD*60)\n\n    # We have to go in chunks of 100 volumes\
          \ (now, dimensionCriteria) otherwise \n    # Error: The collection MetricDataQueries\
          \ must not have a size greater than 100.\n    # This is a limitation of\
          \ the AWS CloudWatch API\n    for dimensionChunk in chunks(dimensionCriteria,100):\n\
          \        # If the period is 5 minutes and the time is now 09:39 request\
          \ from\n        # 09:30 - 09:35\n        # The intent is to get a full section\
          \ of data; since 09:35-09:39 isn't a full period,\n        # the data might\
          \ be unreliable.\n        for response in volumeDataPager.paginate(\n  \
          \                      StartTime=time_start-(datetime.timedelta(minutes=CLOUDWATCH_PERIOD)\
          \ * 2),\n                        EndTime=time_start-datetime.timedelta(minutes=CLOUDWATCH_PERIOD),\n\
          \                        MetricDataQueries=dimensionChunk,\n           \
          \         ):\n            for mdr in response['MetricDataResults']:\n  \
          \              if len(mdr['Values']) > 0:\n                    seen_volumes.add(mdr['Label'])\n\
          \                    ACTIVE_VOLUMES.add(mdr['Label'])\n                \
          \    EBS_IOPS.labels(vol_id=mdr['Label']).set(mdr['Values'][0])\n      \
          \              logging.debug(\"%s has Values\",mdr['Label'])\n         \
          \       else:\n                    logging.debug(\"%s has no Values\", mdr['Label'])\n\
          \n    logging.debug(\"Have %d ACTIVE_VOLUMES, seen %d volumes, total volumes\
          \ from list_metrics %d\",len(ACTIVE_VOLUMES),len(seen_volumes),len(volumes))\
          \    \n    for inactive_volume in ACTIVE_VOLUMES - seen_volumes:\n     \
          \   logging.info(\"Removing vol_id='%s' from Prometheus \",inactive_volume)\n\
          \        EBS_IOPS.remove(inactive_volume)\n        ACTIVE_VOLUMES.remove(inactive_volume)\n\
          \nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO,\
          \ format='%(asctime)s %(levelname)s:%(name)s:%(message)s')\n    \n    parser\
          \ = argparse.ArgumentParser(description='Options for EBS IOPS Exporter')\n\
          \    parser.add_argument('-p', '--aws-profile', help='Name of AWS credentials\
          \ profile to use', required=False, default=\"default\")\n    parser.add_argument('-r',\
          \ '--aws-region', help='AWS Regiom to use', required=False, default=\"us-east-1\"\
          )\n    args = vars(parser.parse_args())\n   \n    # Preference order for\
          \ the AWS profile:\n    # 1. Environment variables (AWS_PROFILE)\n    #\
          \ 2. Argument to program (--aws-profile)\n    # 3. \"default\", if neither\
          \ are specified\n\n    if \"AWS_PROFILE\" in os.environ:\n        args['aws_profile']\
          \ = os.environ['AWS_PROFILE']\n\n    logging.info(\"Starting ebs-iops-reporter\
          \ with aws_profile=%s, aws_region=%s\",args['aws_profile'],args['aws_region'])\n\
          \n    session = boto3.session.Session(profile_name=args['aws_profile'],region_name=args['aws_region'])\n\
          \    cw = session.client('cloudwatch')\n\n    start_http_server(8080)\n\
          \    while True:\n        collect(cw)\n        # Sleep for the interval\n\
          \        logging.info(\"Going to sleep for %d seconds\",CLOUDWATCH_PERIOD*60)\n\
          \        time.sleep(CLOUDWATCH_PERIOD * 60)\n"
        start.sh: "#!/bin/sh\n\nset -o allexport\n\nif [[ -d /config && -d /config/env\
          \ ]]; then\n  source /config/env/*\nfi\n\nexec /usr/bin/python /monitor/main.py\
          \ \"$@\""
      kind: ConfigMap
      metadata:
        creationTimestamp: null
        name: sre-ebs-iops-reporter-code
        namespace: openshift-monitoring
    - apiVersion: apps.openshift.io/v1
      kind: DeploymentConfig
      metadata:
        labels:
          name: sre-ebs-iops-reporter
        name: sre-ebs-iops-reporter
        namespace: openshift-monitoring
      spec:
        paused: false
        replicas: 1
        selector:
          name: sre-ebs-iops-reporter
        strategy:
          type: Recreate
        template:
          metadata:
            labels:
              name: sre-ebs-iops-reporter
            name: sre-ebs-iops-reporter
          spec:
            containers:
            - command:
              - /bin/sh
              - /monitor/start.sh
              env:
              - name: AWS_SHARED_CREDENTIALS_FILE
                value: /secrets/aws/credentials.ini
              - name: AWS_CONFIG_FILE
                value: /secrets/aws/config.ini
              - name: PYTHONPATH
                value: /openshift-python/packages:/support/packages
              image: quay.io/jupierce/openshift-python-monitoring:stable
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 2
                httpGet:
                  path: /
                  port: 8080
                initialDelaySeconds: 420
                periodSeconds: 360
                timeoutSeconds: 240
              name: main
              ports:
              - containerPort: 8080
                protocol: TCP
              readinessProbe:
                httpGet:
                  path: /
                  port: 8080
                initialDelaySeconds: 3
                timeoutSeconds: 240
              volumeMounts:
              - mountPath: /monitor
                name: monitor-volume
                readOnly: true
              - mountPath: /config
                name: envfiles
                readOnly: true
              - mountPath: /secrets
                name: secrets
                readOnly: true
              workingDir: /monitor
            dnsPolicy: ClusterFirst
            initContainers:
            - command:
              - /usr/local/bin/init.py
              - -r
              - /secrets/aws/config.ini
              - -a
              - /rawsecrets/aws_access_key_id
              - -A
              - /rawsecrets/aws_secret_access_key
              - -o
              - /secrets/aws/credentials.ini
              - -c
              - /config/env/CLUSTERID
              image: quay.io/openshift-sre/managed-prometheus-exporter-initcontainer:v0.1.9-2019-03-28-4e558131
              name: setupcreds
              volumeMounts:
              - mountPath: /rawsecrets
                name: awsrawcreds
                readOnly: true
              - mountPath: /secrets
                name: secrets
              - mountPath: /config
                name: envfiles
            restartPolicy: Always
            serviceAccountName: sre-ebs-iops-reporter
            volumes:
            - name: awsrawcreds
              secret:
                secretName: sre-ebs-iops-reporter-aws-credentials
            - emptyDir: {}
              name: secrets
            - emptyDir: {}
              name: envfiles
            - configMap:
                name: sre-ebs-iops-reporter-code
              name: monitor-volume
        triggers:
        - type: ConfigChange
    - apiVersion: v1
      kind: Service
      metadata:
        labels:
          name: sre-ebs-iops-reporter
        name: sre-ebs-iops-reporter
        namespace: openshift-monitoring
      spec:
        ports:
        - name: http-main
          port: 80
          protocol: TCP
          targetPort: 8080
        selector:
          name: sre-ebs-iops-reporter
        sessionAffinity: None
        type: ClusterIP
    - apiVersion: monitoring.coreos.com/v1
      kind: ServiceMonitor
      metadata:
        labels:
          k8s-app: sre-ebs-iops-reporter
          name: sre-ebs-iops-reporter
        name: sre-ebs-iops-reporter
        namespace: openshift-monitoring
      spec:
        endpoints:
        - honorLabels: true
          interval: 2m
          port: http-main
          scheme: http
          scrapeTimeout: 2m
          targetPort: 0
        jobLabel: sre-ebs-iops-reporter
        namespaceSelector: {}
        selector:
          matchLabels:
            name: sre-ebs-iops-reporter
parameters:
- name: IMAGE_TAG
  required: true
  value: latest
